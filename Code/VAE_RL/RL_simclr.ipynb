{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f097689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import os\n",
    "import torch\n",
    "from stable_baselines3 import SAC\n",
    "import random\n",
    "import gymnasium as gym\n",
    "from PIL import Image\n",
    "import time\n",
    "from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback, EvalCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gymnasium import ObservationWrapper\n",
    "from gymnasium.wrappers import PixelObservationWrapper, FrameStack\n",
    "from gymnasium.spaces import Box, Discrete\n",
    "import numpy as np\n",
    "import yaml\n",
    "from torchvision import transforms\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3584b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"MountainCarContinuous-v0\"\n",
    "#env_name = \"MountainCar-v0\"\n",
    "env= gym.make(env_name,render_mode ='rgb_array')\n",
    "env = PixelObservationWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "756f8a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/miniconda3/envs/simclr/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "obs,_ = env.reset()\n",
    "frame = obs['pixels']\n",
    "val_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "        #AddGaussianNoise(self.mean, self.std),\n",
    "        transforms.Resize((64,64))\n",
    "        ])\n",
    "frame = val_transforms(frame) #(c,h,w)\n",
    "frame = torch.unsqueeze(frame, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f90662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec85406c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512]) torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "h, _, enc, zj = model(frame, frame)\n",
    "print(h.shape, z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a9da4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc[0]-zj[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba5efdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array([tensor.detach().cpu().numpy() for tensor in enc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc81f5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c79427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the wrapper\n",
    "class VAE_ENC(ObservationWrapper):\n",
    "    def __init__(self, env, vae,\n",
    "                 mean=0,std=0.1,\n",
    "                 size=(64,64)):\n",
    "        super().__init__(env)\n",
    "        #new obs space\n",
    "        self.observation_space = Box(shape=(64,), low=-np.inf, high=np.inf)\n",
    "\n",
    "        self.vae = vae\n",
    "        #transforms\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.size = size\n",
    "        \n",
    "        \n",
    "        \n",
    "    def observation(self, obs):\n",
    "        #get frame\n",
    "        #print(obs)\n",
    "        frame = obs['pixels']#.to('cuda')\n",
    "        #transform for VAE\n",
    "        val_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        #AddGaussianNoise(self.mean, self.std),\n",
    "        transforms.Resize(self.size),\n",
    "        #transforms.Grayscale(),\n",
    "        #transforms.Normalize(self.mean, self.std),\n",
    "        ])\n",
    "        frame = val_transforms(frame).to('cpu') #(c,h,w)\n",
    "        frame = torch.unsqueeze(frame, 0)#.to(self.device) #make it (1,c,h,w)\n",
    "        res_net,res_net1,enc,enc_1 = self.vae(frame, frame)  # takes two pictures, bc loss is comparrison\n",
    "        # outputs resnet for both pictures, and enc in feature dim\n",
    "        enc = np.array([tensor.detach().cpu().numpy() for tensor in enc])\n",
    "        enc = np.array(enc[0])\n",
    "        return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2250af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cpu')#(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "PATH = \"third_lunar_64.pth\" #\"model_architecture.pth\"#\"model_mountain_car.pth\"\n",
    "#device = torch.device('gpu')\n",
    "model = torch.load(PATH, map_location=device)\n",
    "\n",
    "env_name = \"LunarLander-v2\" #\"MountainCarContinuous-v0\"\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\",\n",
    "                continuous= True,\n",
    "                gravity= -10.0,\n",
    "                enable_wind= False,\n",
    "                wind_power= 15.0,\n",
    "                turbulence_power= 1.5,\n",
    "                render_mode ='rgb_array')\n",
    "\n",
    "#env_name = \"MountainCar-v0\"\n",
    "#env= gym.make(env_name,render_mode ='rgb_array')\n",
    "env = PixelObservationWrapper(env)\n",
    "env = VAE_ENC(env, model)\n",
    "env = FrameStack(env, num_stack=2)\n",
    "env = Monitor(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6378a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/miniconda3/envs/simclr/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "obs, info=env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46361410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b46b252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_train_steps = 500000 #episode max_len=999 -> ~50 episodes\n",
    "agent_name = \"simclr64_2_agent_data_SAC\"\n",
    "env_name = \"LunarLander-v2\"\n",
    "seed = 42\n",
    "i=2\n",
    "models_dir = f\"RLmodels/\"+env_name\n",
    "logdir = f\"RLlogs/\"+env_name\n",
    "\n",
    "callback = CheckpointCallback(save_freq=10000, save_path=models_dir+str(i))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71ec7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SAC(\n",
    "    env = env,\n",
    "    policy= 'MlpPolicy',\n",
    "    batch_size= 128,\n",
    "    learning_rate=0.0003,\n",
    "    buffer_size= 100000, #1000000,\n",
    "    ent_coef='auto',\n",
    "    gamma= 0.99,\n",
    "    tau= 0.01,\n",
    "    train_freq= 1,\n",
    "    gradient_steps= 1,\n",
    "    learning_starts= 10000,\n",
    "    policy_kwargs= dict(net_arch=[400,300]),#dict(net_arch=[400, 300])\n",
    "    tensorboard_log=logdir+str(i)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "832a2713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x7fff809a7e10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.learn(total_timesteps=RL_train_steps,callback=callback,tb_log_name=agent_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da5045cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Monitor<FrameStack<VAE_ENC<PixelObservationWrapper<TimeLimit<OrderEnforcing<PassiveEnvChecker<LunarLander<LunarLander-v2>>>>>>>>>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be3da30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SAC.load('RLmodels/LunarLander-v2/rl_model_480000_steps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb4033bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path='agent_data'\n",
    "data_name='simclr64SAC_after_third_train'\n",
    "num_of_episodes=100\n",
    "i=0\n",
    "for episode in range(num_of_episodes):\n",
    "    observation, info = env.reset()\n",
    "    done = False\n",
    "    while not done: \n",
    "        action, _states = agent.predict(observation, deterministic=True)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        #state, reward, terminated, truncated, info = env.step(action)\n",
    "        #print(terminated, truncated)\n",
    "        if terminated:\n",
    "            done = True\n",
    "        if truncated:\n",
    "            done = True\n",
    "        current_frame = env.render()\n",
    "\n",
    "        i+=1\n",
    "        im = Image.fromarray(np.array(current_frame))\n",
    "        im.save(save_path+'/'+data_name+'_'+str(i)+'.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cff9a3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16585077,  0.76528394], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608a668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name='initial_random_action'\n",
    "save_path='Data/lunar-lander/'+data_name+'/'\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\",\n",
    "                continuous= True,\n",
    "                gravity= -10.0,\n",
    "                enable_wind= False,\n",
    "                wind_power= 15.0,\n",
    "                turbulence_power= 1.5,\n",
    "                render_mode ='rgb_array')\n",
    "\n",
    "num_of_episodes=100\n",
    "i=0\n",
    "for episode in range(num_of_episodes):\n",
    "    observation, info = env.reset()\n",
    "    done = False\n",
    "    while not done: \n",
    "        action= env.env.action_space.sample()\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        #state, reward, terminated, truncated, info = env.step(action)\n",
    "        #print(terminated, truncated)\n",
    "        if terminated:\n",
    "            done = True\n",
    "        if truncated:\n",
    "            done = True\n",
    "        current_frame = env.render()\n",
    "\n",
    "        i+=1\n",
    "        im = Image.fromarray(np.array(current_frame))\n",
    "        im.save(save_path+'/'+data_name+'_'+str(i)+'.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a0b1d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SAC(   \n",
    "    policy='MlpPolicy',\n",
    "    env=env,\n",
    "    seed=seed,\n",
    "    learning_rate=0.0003,\n",
    "    buffer_size= 50000,\n",
    "    batch_size= 512,\n",
    "    ent_coef= 0.1,\n",
    "    train_freq= 32,\n",
    "    gradient_steps= 32,\n",
    "    gamma= 0.9999,\n",
    "    tau= 0.01,\n",
    "    learning_starts= 0,\n",
    "    use_sde= True,\n",
    "    policy_kwargs= dict(log_std_init=-3.67, net_arch=[64, 64]),\n",
    "    tensorboard_log=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d048e35a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
