{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562be77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. init data\n",
    "2. train vae\n",
    "3. use vae as wrapper for env\n",
    "4. make other wrappers, prepro, frame stack, FRAME CAPTURE\n",
    "5. train rl, gather ne imgs with capture wrapper ( also capture actions for rl)\n",
    "6. if n of new img == num of old imgs\n",
    "    Retrain vae\n",
    "    else continue rl training and img gathering\n",
    "7. continou train vae\n",
    "8. performance check of rl:\n",
    "    if better or == to previous performance\n",
    "    continou training that rl and collecting imgs with it\n",
    "    else train completle new rl as often until its better than previous.. \n",
    "    if it doesnt work\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ac0271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import numpy as np\n",
    "import yaml\n",
    "from PIL import Image\n",
    "from experiment import VAEXperiment\n",
    "from models import *\n",
    "\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import ObservationWrapper\n",
    "from gymnasium.wrappers import PixelObservationWrapper, FrameStack\n",
    "from gymnasium.spaces import Box, Discrete\n",
    "\n",
    "\n",
    "\n",
    "from stable_baselines3 import SAC, PPO, A2C\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback, EvalCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29bf7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import ObservationWrapper\n",
    "from gymnasium.wrappers import PixelObservationWrapper, FrameStack\n",
    "from gymnasium.spaces import Box, Discrete\n",
    "import numpy as np\n",
    "import yaml\n",
    "from experiment import VAEXperiment\n",
    "from models import *\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=0.1):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "#ideas\n",
    "#maybe use wrapper to catch and save frames during RL model learning\n",
    "#alternative is to use the model afterwards to generate frames during a test run\n",
    "#\n",
    "#??return mu, std or sample or just mu??\n",
    "#\n",
    "class VAE_ENC(ObservationWrapper):\n",
    "    def __init__(self, env, vae, latent_dim,\n",
    "                 mean=0,std=0.1,\n",
    "                 size=(64,64),\n",
    "                 collect_frames_dir = None,\n",
    "                 start_index = 0):\n",
    "        super().__init__(env)\n",
    "        #new obs space with std\n",
    "        #self.observation_space = Box(shape=(2, latent_dim), low=-np.inf, high=np.inf)\n",
    "        #just mean\n",
    "        self.observation_space = Box(shape=(latent_dim,), low=-np.inf, high=np.inf)\n",
    "        \n",
    "        self.vae = vae\n",
    "        #transforms\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.size = size\n",
    "        \n",
    "        self.collect_frames_dir = collect_frames_dir\n",
    "        self.frame_idx = start_index\n",
    "        \n",
    "        \n",
    "        \n",
    "    def observation(self, obs):\n",
    "        #get frame\n",
    "        #print(obs)\n",
    "        frame = obs['pixels']#.to('cuda')\n",
    "        if self.collect_frames_dir == None:\n",
    "            im = Image.fromarray(np.array(frame))\n",
    "            im.save(self.collect_frames_dir+'_'+str(self.frame_idx)+'.jpeg')\n",
    "            self.frame_idx += 1\n",
    "        #transform for VAE\n",
    "        val_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        AddGaussianNoise(self.mean, self.std),\n",
    "        transforms.Resize(self.size),\n",
    "        #transforms.Grayscale(),\n",
    "        #transforms.Normalize(self.mean, self.std),\n",
    "        ])\n",
    "        frame = val_transforms(frame) #(c,h,w)\n",
    "        frame = torch.unsqueeze(frame, 0)#.to(self.device) #make it (1,c,h,w)\n",
    "        enc = self.vae.encode(frame)    \n",
    "        enc = np.array([tensor.detach().cpu().numpy() for tensor in enc])\n",
    "        #with std\n",
    "        #enc = np.array([enc[0][0], enc[1][0]]) ## mu, std #  give only mu?\n",
    "        #just mean\n",
    "        enc = np.array(enc[0][0])\n",
    "        \n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "        return enc\n",
    "    \n",
    "def get_vae(version='version_0',log_directory='logs/BCE_sum_VAE/MSSIMVAE/'):\n",
    "\n",
    "    model_path=log_directory+'/'+version+'/hparams.yaml'\n",
    "    ckpt_path=log_directory+'/'+version+'/checkpoints/last.ckpt'\n",
    "\n",
    "    config = yaml.safe_load(open(model_path))\n",
    "    model = vae_models[config['model_params']['name']](**config['model_params'])\n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    experiment = VAEXperiment(model, config['exp_params'])\n",
    "    experiment.load_state_dict(ckpt['state_dict'])      \n",
    "    vae = experiment.model\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c094c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name='wrapper_test'\n",
    "save_path='Data/MountainCar/'+data_name+'/'\n",
    "\n",
    "vae = get_vae(version='version_13',log_directory='logs/MountainCar/BCE_sum_VAE_2/MSSIMVAE/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f92145",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MountainCarContinuous-v0\",\n",
    "                render_mode ='rgb_array')\n",
    "seed = 42\n",
    "env.reset(seed=seed)\n",
    "env = PixelObservationWrapper(env)\n",
    "env = VAE_ENC(env, vae, 2, collect_frames_dir = save_path)\n",
    "env = FrameStack(env, num_stack=2)\n",
    "env = Monitor(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5259f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f1c48a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6710f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "class frame_saver(ObservationWrapper):\n",
    "    def __init__(self, env,\n",
    "                 collect_frames_dir = None,\n",
    "                 start_index = 0):\n",
    "        super().__init__(env)\n",
    "        \n",
    "        self.collect_frames_dir = collect_frames_dir\n",
    "        self.frame_idx = start_index\n",
    "                \n",
    "        \n",
    "    def observation(self, obs):\n",
    "        frame = obs['pixels']#.to('cuda')\n",
    "        if self.collect_frames_dir != None:\n",
    "            im = Image.fromarray(np.array(frame))\n",
    "            im.save(self.collect_frames_dir+'_'+str(self.frame_idx)+'.jpeg')\n",
    "            self.frame_idx += 1\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25a97c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_env(env_id: str = \"MountainCarContinuous-v0\", rank: int = 0, seed: int = 42) -> Callable:\n",
    "    def _init() -> gym.Env:\n",
    "        data_name='wrapper_test'\n",
    "        save_path='Data/MountainCar/'+data_name+'/real_eval_env_'+str(rank)+'_'\n",
    "        vae = get_vae(version='version_13',log_directory='logs/MountainCar/BCE_sum_VAE_2/MSSIMVAE/')\n",
    "        \n",
    "        env = gym.make(env_id,\n",
    "                    render_mode ='rgb_array')\n",
    "        seed = 42\n",
    "        env.reset(seed=seed + rank)\n",
    "        env = PixelObservationWrapper(env)\n",
    "        env = frame_saver(env, save_path)\n",
    "        env = VAE_ENC(env, vae, 2, collect_frames_dir = save_path)\n",
    "        env = FrameStack(env, num_stack=2)\n",
    "        env = Monitor(env)\n",
    "        return env\n",
    "    set_random_seed(seed)\n",
    "    return _init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ef3bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"MountainCarContinuous-v0\"\n",
    "num_cpu = 2  # Number of processes to use\n",
    "# Create the vectorized environment\n",
    "env = SubprocVecEnv([make_env(env_id, i) for i in range(num_cpu)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50f44640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned\n",
    "agent = A2C(\n",
    "\n",
    "    env = env,\n",
    "    n_steps= 100,\n",
    "    \n",
    "    policy='MlpPolicy',\n",
    "    ent_coef= 0.0,\n",
    "    use_sde=True,\n",
    "    sde_sample_freq = 16,\n",
    "    policy_kwargs= dict(log_std_init=0.0, ortho_init=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bbdfd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7f5ec2d6fa60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RL_train_steps = 10\n",
    "agent.learn(total_timesteps=RL_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8f5136",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"MountainCarContinuous-v0\"\n",
    "num_cpu = 2 \n",
    "eval_env = SubprocVecEnv([make_env(env_id, i) for i in range(num_cpu)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff47b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward = evaluate_policy(agent, eval_env, n_eval_episodes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9fa11a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
