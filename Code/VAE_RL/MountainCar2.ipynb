{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ebffa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import numpy as np\n",
    "import yaml\n",
    "from PIL import Image\n",
    "from experiment import VAEXperiment\n",
    "from models import *\n",
    "\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import ObservationWrapper\n",
    "from gymnasium.wrappers import PixelObservationWrapper, FrameStack\n",
    "from gymnasium.spaces import Box, Discrete\n",
    "\n",
    "\n",
    "\n",
    "from stable_baselines3 import SAC, PPO, A2C\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback, EvalCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "742af501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import ObservationWrapper\n",
    "from gymnasium.wrappers import PixelObservationWrapper, FrameStack\n",
    "from gymnasium.spaces import Box, Discrete\n",
    "import numpy as np\n",
    "import yaml\n",
    "from experiment import VAEXperiment\n",
    "from models import *\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=0.1):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "#ideas\n",
    "#maybe use wrapper to catch and save frames during RL model learning\n",
    "#alternative is to use the model afterwards to generate frames during a test run\n",
    "#\n",
    "#??return mu, std or sample or just mu??\n",
    "#\n",
    "class VAE_ENC(ObservationWrapper):\n",
    "    def __init__(self, env, vae, latent_dim,\n",
    "                 mean=0,std=0.1,\n",
    "                 size=(64,64)):\n",
    "        super().__init__(env)\n",
    "        #new obs space with std\n",
    "        #self.observation_space = Box(shape=(2, latent_dim), low=-np.inf, high=np.inf)\n",
    "        #just mean\n",
    "        self.observation_space = Box(shape=(latent_dim,), low=-np.inf, high=np.inf)\n",
    "        \n",
    "        self.vae = vae\n",
    "        #transforms\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.size = size\n",
    "        \n",
    "        \n",
    "        \n",
    "    def observation(self, obs):\n",
    "        #get frame\n",
    "        #print(obs)\n",
    "        frame = obs['pixels']#.to('cuda')\n",
    "        #transform for VAE\n",
    "        val_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        AddGaussianNoise(self.mean, self.std),\n",
    "        transforms.Resize(self.size),\n",
    "        #transforms.Grayscale(),\n",
    "        #transforms.Normalize(self.mean, self.std),\n",
    "        ])\n",
    "        frame = val_transforms(frame) #(c,h,w)\n",
    "        frame = torch.unsqueeze(frame, 0)#.to(self.device) #make it (1,c,h,w)\n",
    "        enc = self.vae.encode(frame)    \n",
    "        enc = np.array([tensor.detach().cpu().numpy() for tensor in enc])\n",
    "        #with std\n",
    "        #enc = np.array([enc[0][0], enc[1][0]]) ## mu, std #  give only mu?\n",
    "        #just mean\n",
    "        enc = np.array(enc[0][0])\n",
    "        return enc\n",
    "    \n",
    "def get_vae(version='version_0',log_directory='logs/BCE_sum_VAE/MSSIMVAE/'):\n",
    "\n",
    "    model_path=log_directory+'/'+version+'/hparams.yaml'\n",
    "    ckpt_path=log_directory+'/'+version+'/checkpoints/last.ckpt'\n",
    "\n",
    "    config = yaml.safe_load(open(model_path))\n",
    "    model = vae_models[config['model_params']['name']](**config['model_params'])\n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    experiment = VAEXperiment(model, config['exp_params'])\n",
    "    experiment.load_state_dict(ckpt['state_dict'])      \n",
    "    vae = experiment.model\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3814923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name='PPO_data_10ep_random_init'\n",
    "save_path='Data/MountainCar/'+data_name+'/'\n",
    "\n",
    "\n",
    "env = gym.make(\"MountainCarContinuous-v0\",\n",
    "                render_mode ='rgb_array')\n",
    "\n",
    "num_of_episodes=10\n",
    "i=0\n",
    "for episode in range(num_of_episodes):\n",
    "    observation, info = env.reset()\n",
    "    done = False\n",
    "    while not done: \n",
    "        action= env.env.action_space.sample()\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        #state, reward, terminated, truncated, info = env.step(action)\n",
    "        #print(terminated, truncated)\n",
    "        if terminated:\n",
    "            done = True\n",
    "        if truncated:\n",
    "            done = True\n",
    "        current_frame = env.render()\n",
    "\n",
    "        i+=1\n",
    "        im = Image.fromarray(np.array(current_frame))\n",
    "        im.save(save_path+data_name+'_'+str(i)+'.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f906ebb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25b42004",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = get_vae(version='version_3',log_directory='logs/MountainCar/BCE_sum_VAE_1/MSSIMVAE/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2896f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MountainCarContinuous-v0\",\n",
    "                render_mode ='rgb_array')\n",
    "seed = 42\n",
    "env.reset(seed=seed)\n",
    "env = PixelObservationWrapper(env)\n",
    "env = VAE_ENC(env, vae, 1)\n",
    "env = FrameStack(env, num_stack=2)\n",
    "env = Monitor(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4816106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "agent_name = \"PPO_OG\"\n",
    "\n",
    "env_name = \"MountainCarContinuous-v0\"\n",
    "\n",
    "models_dir = f\"RLmodels/\"+env_name+'/'+agent_name\n",
    "logdir = f\"RLlogs/\"+env_name+'/OG_PPO'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "RL_train_steps = 100000\n",
    "\n",
    "callback = CheckpointCallback(save_freq=10000, save_path=models_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27bd8d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/miniconda3/envs/myenv/lib/python3.9/site-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 256, but because the `RolloutBuffer` is of size `n_steps * n_envs = 8`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 8\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=8 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#tuned\n",
    "env = gym.make(\"MountainCarContinuous-v0\",\n",
    "                render_mode ='rgb_array')\n",
    "agent = PPO(\n",
    "  env=env,\n",
    "  policy= 'MlpPolicy',\n",
    "  batch_size= 256,\n",
    "  n_steps= 8,\n",
    "  gamma= 0.9999,\n",
    "  learning_rate= 7.77e-05,\n",
    "  ent_coef= 0.00429,\n",
    "  clip_range= 0.1,\n",
    "  n_epochs=10,\n",
    "  gae_lambda= 0.9,\n",
    "  max_grad_norm=5,\n",
    "  vf_coef= 0.19,\n",
    "  use_sde= True,\n",
    "  policy_kwargs=dict(log_std_init=-3.29, ortho_init=False),\n",
    "  tensorboard_log=logdir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651fd802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7fd8e40c45b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.learn(total_timesteps=RL_train_steps, \n",
    "            tb_log_name=agent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69ca51bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(itera)[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4673217a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/miniconda3/envs/myenv/lib/python3.9/site-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 256, but because the `RolloutBuffer` is of size `n_steps * n_envs = 8`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 8\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=8 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "itera=20\n",
    "i =10\n",
    "for i in range(itera):\n",
    "    agent_name = \"PPO_tuned_OG\"+str(i)\n",
    "\n",
    "    env_name = \"MountainCarContinuous-v0\"\n",
    "\n",
    "    #models_dir = f\"RLmodels/\"+env_name+'/'+agent_name\n",
    "    logdir = f\"RLlogs/\"+env_name+'/OG_PPO'\n",
    "    #os.makedirs(models_dir, exist_ok=True)\n",
    "    os.makedirs(logdir, exist_ok=True)\n",
    "    RL_train_steps = 1000000\n",
    "    \n",
    "    #tuned\n",
    "    env = gym.make(\"MountainCarContinuous-v0\",\n",
    "                    render_mode ='rgb_array')\n",
    "    agent = PPO(\n",
    "      env=env,\n",
    "      policy= 'MlpPolicy',\n",
    "      batch_size= 256,\n",
    "      n_steps= 8,\n",
    "      gamma= 0.9999,\n",
    "      learning_rate= 7.77e-05,\n",
    "      ent_coef= 0.00429,\n",
    "      clip_range= 0.1,\n",
    "      n_epochs=10,\n",
    "      gae_lambda= 0.9,\n",
    "      max_grad_norm=5,\n",
    "      vf_coef= 0.19,\n",
    "      use_sde= True,\n",
    "      policy_kwargs=dict(log_std_init=-3.29, ortho_init=False),\n",
    "      tensorboard_log=logdir,\n",
    "    )\n",
    "    agent.learn(total_timesteps=RL_train_steps, \n",
    "            tb_log_name=agent_name)\n",
    "    agent.save(\"RLmodels/MountainCarContinuous-v0/PPO_tuned_OG/\"+agent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d76bf9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/miniconda3/envs/myenv/lib/python3.9/site-packages/stable_baselines3/common/save_util.py:278: UserWarning: Path 'RLmodels/MountainCarContinuous-v0/A2C_tuned_OG' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "itera=10\n",
    "i =1\n",
    "for i in range(itera):\n",
    "    agent_name = \"A2C_tuned_OG\"+str(i)\n",
    "\n",
    "    env_name = \"MountainCarContinuous-v0\"\n",
    "\n",
    "    #models_dir = f\"RLmodels/\"+env_name+'/'+agent_name\n",
    "    logdir = f\"RLlogs/\"+env_name+'/OG_A2C'\n",
    "    #os.makedirs(models_dir, exist_ok=True)\n",
    "    os.makedirs(logdir, exist_ok=True)\n",
    "    RL_train_steps = 1000000\n",
    "    \n",
    "    #tuned\n",
    "    env = gym.make(\"MountainCarContinuous-v0\",\n",
    "                    render_mode ='rgb_array')\n",
    "    agent = A2C(\n",
    "\n",
    "        env = env,\n",
    "        n_steps= 100,\n",
    "\n",
    "        policy='MlpPolicy',\n",
    "        ent_coef= 0.0,\n",
    "        use_sde=True,\n",
    "        sde_sample_freq = 16,\n",
    "        policy_kwargs= dict(log_std_init=0.0, ortho_init=False),\n",
    "        tensorboard_log=logdir)\n",
    "    agent.learn(total_timesteps=RL_train_steps, \n",
    "            tb_log_name=agent_name)\n",
    "    agent.save(\"RLmodels/MountainCarContinuous-v0/A2C_tuned_OG/\"+agent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9efadbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/miniconda3/envs/myenv/lib/python3.9/site-packages/stable_baselines3/common/save_util.py:278: UserWarning: Path 'RLmodels/MountainCarContinuous-v0/SAC_tuned_OG' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "itera=10\n",
    "i =1\n",
    "for i in range(itera):\n",
    "    agent_name = \"SAC_tuned_OG\"+str(i)\n",
    "\n",
    "    env_name = \"MountainCarContinuous-v0\"\n",
    "\n",
    "    #models_dir = f\"RLmodels/\"+env_name+'/'+agent_name\n",
    "    logdir = f\"RLlogs/\"+env_name+'/OG_SAC'\n",
    "    #os.makedirs(models_dir, exist_ok=True)\n",
    "    os.makedirs(logdir, exist_ok=True)\n",
    "    RL_train_steps = 200000\n",
    "    \n",
    "    #tuned\n",
    "    env = gym.make(\"MountainCarContinuous-v0\",\n",
    "                    render_mode ='rgb_array')\n",
    "    agent = SAC(\n",
    "        env = env,\n",
    "        policy = 'MlpPolicy',\n",
    "        learning_rate= 0.0003,\n",
    "        buffer_size= 50000,\n",
    "        batch_size= 512,\n",
    "        ent_coef= 0.1,\n",
    "        train_freq= 32,\n",
    "        gradient_steps= 32,\n",
    "        gamma= 0.9999,\n",
    "        tau= 0.01,\n",
    "        learning_starts= 0,\n",
    "        use_sde= True,\n",
    "        policy_kwargs= dict(log_std_init=-3.67, net_arch=[64, 64]),\n",
    "        tensorboard_log=logdir\n",
    "    )\n",
    "    agent.learn(total_timesteps=RL_train_steps, \n",
    "            tb_log_name=agent_name)\n",
    "    agent.save(\"RLmodels/MountainCarContinuous-v0/SAC_tuned_OG/\"+agent_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c99c47c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7ff5c8045a60>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.learn(total_timesteps=RL_train_steps, \n",
    "            callback=callback,\n",
    "            tb_log_name=agent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77ead845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned\n",
    "agent = A2C(\n",
    "\n",
    "    env = env,\n",
    "    n_steps= 100,\n",
    "    \n",
    "    policy='MlpPolicy',\n",
    "    ent_coef= 0.0,\n",
    "    use_sde=True,\n",
    "    sde_sample_freq = 16,\n",
    "    policy_kwargs= dict(log_std_init=0.0, ortho_init=False),\n",
    "    tensorboard_log=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cbaa067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7fa544cc26d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.learn(total_timesteps=RL_train_steps, \n",
    "            callback=callback,\n",
    "            tb_log_name=agent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad341dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c361f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e02fc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "agent_name = \"vae_1_v2_agent_2_PPO\"\n",
    "\n",
    "env_name = \"MountainCarContinuous-v0\"\n",
    "\n",
    "models_dir = f\"RLmodels/\"+env_name+'/'+agent_name\n",
    "model_dir = Path(models_dir)\n",
    "model_list = sorted([f for f in model_dir.iterdir() if f.suffix == '.zip'])\n",
    "print(len(model_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70301bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rl_model_100000_steps'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(model_list[0])[55:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74dcd32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('RLmodels/MountainCarContinuous-v0/vae_2_v6_agent_3_A2C/rl_model_100000_steps.zip')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e836fa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rl_model_100000_steps\n",
      "rl_model_10000_steps\n",
      "rl_model_20000_steps\n",
      "rl_model_30000_steps\n",
      "rl_model_40000_steps\n",
      "rl_model_50000_steps\n",
      "rl_model_60000_steps\n",
      "rl_model_70000_steps\n",
      "rl_model_80000_steps\n",
      "rl_model_90000_steps\n"
     ]
    }
   ],
   "source": [
    "iteration = '2'\n",
    "vae_version ='2'\n",
    "for model in model_list:\n",
    "    model = str(model)[55:-4] #[43:-4]\n",
    "    print(model)\n",
    "    agent= PPO.load(models_dir+'/'+model)\n",
    "    #save_path='Data/MountainCar/vae_A2C_'+iteration+'_rl_model'\n",
    "    data_name='vae_'+vae_version+'_PP0_'+iteration+'_'+model+'_'\n",
    "    num_of_episodes=2\n",
    "    i=0\n",
    "    for episode in range(num_of_episodes):\n",
    "        observation, info = env.reset()\n",
    "        done = False\n",
    "        while not done: \n",
    "            action, _states = agent.predict(observation, deterministic=False)\n",
    "            observation, reward, terminated, truncated, info = env.step(action)\n",
    "            #state, reward, terminated, truncated, info = env.step(action)\n",
    "            #print(terminated, truncated)\n",
    "            if terminated:\n",
    "                done = True\n",
    "            if truncated:\n",
    "                done = True\n",
    "            current_frame = env.render()\n",
    "\n",
    "            i+=1\n",
    "            im = Image.fromarray(np.array(current_frame))\n",
    "            im.save('Data/MountainCar/PPO_data_10ep_random_init/'+data_name+'_'+str(i)+'.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94355c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rl_model_660000_steps\n"
     ]
    }
   ],
   "source": [
    "model = 'rl_model_660000_steps'\n",
    "agent_name = \"vae_2_v12_agent_2_A2C_long\"\n",
    "\n",
    "env_name = \"MountainCarContinuous-v0\"\n",
    "\n",
    "models_dir = f\"RLmodels/\"+env_name+'/'+agent_name\n",
    "\n",
    "iteration = '2'\n",
    "print(model)\n",
    "agent= PPO.load(models_dir+'/'+model)\n",
    "#save_path='Data/MountainCar/vae_A2C_'+iteration+'_rl_model'\n",
    "data_name='vae_A2C_'+iteration+'_'+model+'_'\n",
    "\n",
    "\n",
    "num_of_episodes=80\n",
    "\n",
    "num_of_img=9990\n",
    "i=0\n",
    "for episode in range(num_of_episodes):\n",
    "    observation, info = env.reset()\n",
    "    done = False\n",
    "    while not done: \n",
    "        action, _states = agent.predict(observation, deterministic=True)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        #state, reward, terminated, truncated, info = env.step(action)\n",
    "        #print(terminated, truncated)\n",
    "        if terminated:\n",
    "            done = True\n",
    "        if truncated:\n",
    "            done = True\n",
    "        current_frame = env.render()\n",
    "\n",
    "        i+=1\n",
    "        im = Image.fromarray(np.array(current_frame))\n",
    "        im.save('Data/MountainCar/init3_agent_2_v12/'+data_name+'_'+str(i)+'.jpeg')\n",
    "        if i == num_of_img:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9118580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdf68ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9990\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "imgs_dir =\"Data/MountainCar/init3_random\"\n",
    "img_dir = Path(imgs_dir)\n",
    "img_list = sorted([f for f in img_dir.iterdir() if f.suffix == '.jpeg'])\n",
    "print(len(img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c919d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i=0\n",
    "for imp in img_list:\n",
    "    im = Image.open(r\"C:\\Users\\System-Pc\\Desktop\\ybear.jpg\") \n",
    "    im.save('Data/MountainCar/init3_random_and_agent_0/'+data_name+'_'+str(i)+'.jpeg')\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
