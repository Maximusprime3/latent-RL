{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5dc54f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import os\n",
    "import torch\n",
    "from stable_baselines3 import SAC\n",
    "import random\n",
    "import gymnasium as gym\n",
    "from PIL import Image\n",
    "import time\n",
    "from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback, EvalCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gymnasium import ObservationWrapper\n",
    "from gymnasium.wrappers import PixelObservationWrapper, FrameStack\n",
    "from gymnasium.spaces import Box, Discrete\n",
    "import numpy as np\n",
    "import yaml\n",
    "from experiment import VAEXperiment\n",
    "from models import *\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "588920b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"LunarLander-v2\",\n",
    "    continuous= True,\n",
    "    gravity= -10.0,\n",
    "    enable_wind= False,\n",
    "    wind_power= 15.0,\n",
    "    turbulence_power= 1.5,\n",
    "    render_mode ='rgb_array'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbb976a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box action space detected.\n",
      "Minimum action values: [-1. -1.]\n",
      "Maximum action values: [1. 1.]\n",
      "Middle action values: [0. 0.]\n",
      "[[-1. -1.]\n",
      " [ 1.  1.]\n",
      " [-1.  1.]\n",
      " [ 1. -1.]\n",
      " [ 0.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0. -1.]\n",
      " [-1.  0.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "action_space = env.action_space\n",
    "low = action_space.low\n",
    "high = action_space.high\n",
    "middle_action = (max_action + min_action) / 2  # Calculate middle action\n",
    "print(\"Box action space detected.\")\n",
    "print(\"Minimum action values:\", min_action)\n",
    "print(\"Maximum action values:\", max_action)\n",
    "print(\"Middle action values:\", middle_action)\n",
    "actions = np.vstack([low, high, [low[0], high[1]], [high[0], low[1]], [0, 0],\n",
    "                     [0, high[1]], [0, low[1]], [low[0], 0], [high[0], 0]])\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf27c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###DATA COLLECTION\n",
    "\n",
    "# collect data with model or random start actions\n",
    "# saves the images \n",
    "# returns num_of_images\n",
    "# save location needs to be specified in VAE configs/hyperparams.yaml\n",
    "# default path is Data/img_Data/img_Data_x.jpeg\n",
    "def collect_imgs(num_of_episodes=2, num_of_previous_imgs =0,\n",
    "                 data_dir=\"Data/\",data_name = \"lunar_Data\",\n",
    "                 model=None,add_all_action_max=False):\n",
    "    \n",
    "    env = gym.make(\"LunarLander-v2\",\n",
    "                    continuous= True,\n",
    "                    gravity= -10.0,\n",
    "                    enable_wind= False,\n",
    "                    wind_power= 15.0,\n",
    "                    turbulence_power= 1.5,\n",
    "                    render_mode ='rgb_array')\n",
    "    obs, info = env.reset()\n",
    "    images = []\n",
    "    #states = []\n",
    "    #actions = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    save_path = data_dir+data_name\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    i=num_of_previous_imgs#img number\n",
    "    \n",
    "    #Random actions\n",
    "    if model == None:\n",
    "        print('start collecting images')\n",
    "        for episode in range(num_of_episodes):\n",
    "            observation, info = env.reset()\n",
    "            done = False\n",
    "            while done == False: \n",
    "                action = env.action_space.sample()\n",
    "                state, reward, terminated, truncated, info = env.step(action)\n",
    "                if terminated:\n",
    "                    done = True\n",
    "                if truncated:\n",
    "                    done = True\n",
    "                current_frame = env.render()\n",
    "                i+=1\n",
    "                im = Image.fromarray(np.array(current_frame))\n",
    "                im.save(save_path+'/'+data_name+'_'+str(i)+'.jpeg')\n",
    "                #images.append(current_frame)\n",
    "                #states.append(state)\n",
    "                #actions.append(action)\n",
    "            print(episode+1,'/',num_of_episodes)\n",
    "    #Model predicts actions\n",
    "    else:\n",
    "        #env needs to be wrapped to the needs of the model\n",
    "        env = PixelObservationWrapper(env)\n",
    "        vae = get_vae(version='version_18')\n",
    "        env = VAE_ENC(env, vae)\n",
    "        env = FrameStack(env, num_stack=2)\n",
    "        env = Monitor(env)\n",
    "        #env = DummyVecEnv([lambda : env])\n",
    "        print('start collecting images with the model')\n",
    "        for episode in range(num_of_episodes):\n",
    "            observation, info = env.reset()\n",
    "            done = False\n",
    "            while not done: \n",
    "                action, _states = model.predict(observation, deterministic=True)\n",
    "                observation, reward, terminated, truncated, info = env.step(action)\n",
    "                #state, reward, terminated, truncated, info = env.step(action)\n",
    "                #print(terminated, truncated)\n",
    "                if terminated:\n",
    "                    done = True\n",
    "                if truncated:\n",
    "                    done = True\n",
    "                current_frame = env.render()\n",
    "\n",
    "                i+=1\n",
    "                im = Image.fromarray(np.array(current_frame))\n",
    "                im.save(save_path+'/'+data_name+'_'+str(i)+'.jpeg')\n",
    "\n",
    "            print(episode+1,'/',num_of_episodes)\n",
    "    #extreme actions for a whole episode each\n",
    "    if add_all_action_max:\n",
    "        action_space = env.action_space\n",
    "        if isinstance(action_space, gym.spaces.Discrete):\n",
    "            # Handle Discrete action space\n",
    "            min_action = 0\n",
    "            max_action = action_space.n - 1\n",
    "            middle_action = (max_action + min_action) // 2  # Calculate middle action\n",
    "            print(\"Discrete action space detected.\")\n",
    "            print(\"Minimum action value:\", min_action)\n",
    "            print(\"Maximum action value:\", max_action)\n",
    "            print(\"Middle action value:\", middle_action)\n",
    "        elif isinstance(action_space, gym.spaces.Box):\n",
    "            # Handle Box action space\n",
    "            low = action_space.low\n",
    "            high = action_space.high            \n",
    "            print(\"Box action space detected.\")\n",
    "            print(\"Minimum action values:\", low)\n",
    "            print(\"Maximum action values:\", high)\n",
    "            \n",
    "            actions = np.vstack([low, high, [low[0], high[1]], [high[0], low[1]], [0, 0],\n",
    "                                 [0, high[1]], [0, low[1]], [low[0], 0], [high[0], 0]])            \n",
    "            print(\"total extreme actions\", len(actions))\n",
    "            \n",
    "        else:\n",
    "            # Handle other types of action space\n",
    "            print(\"Unsupported action space type.\")\n",
    "            \n",
    "        \n",
    "        \n",
    "        for episode in range(len(actions)):\n",
    "            print('start collecting extreme action episode images')\n",
    "            observation, info = env.reset()\n",
    "            done = False\n",
    "            while done == False: \n",
    "                action = actions[episode]\n",
    "                state, reward, terminated, truncated, info = env.step(action)\n",
    "                if terminated:\n",
    "                    done = True\n",
    "                if truncated:\n",
    "                    done = True\n",
    "                current_frame = env.render()\n",
    "\n",
    "                i+=1\n",
    "                im = Image.fromarray(np.array(current_frame))\n",
    "                im.save(save_path+'/'+data_name+'_'+str(i)+'.jpeg')\n",
    "\n",
    "            print(episode+1,'/',len(actions))\n",
    "        \n",
    "\n",
    "    return i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13e16e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start collecting images\n",
      "1 / 50\n",
      "2 / 50\n",
      "3 / 50\n",
      "4 / 50\n",
      "5 / 50\n",
      "6 / 50\n",
      "7 / 50\n",
      "8 / 50\n",
      "9 / 50\n",
      "10 / 50\n",
      "11 / 50\n",
      "12 / 50\n",
      "13 / 50\n",
      "14 / 50\n",
      "15 / 50\n",
      "16 / 50\n",
      "17 / 50\n",
      "18 / 50\n",
      "19 / 50\n",
      "20 / 50\n",
      "21 / 50\n",
      "22 / 50\n",
      "23 / 50\n",
      "24 / 50\n",
      "25 / 50\n",
      "26 / 50\n",
      "27 / 50\n",
      "28 / 50\n",
      "29 / 50\n",
      "30 / 50\n",
      "31 / 50\n",
      "32 / 50\n",
      "33 / 50\n",
      "34 / 50\n",
      "35 / 50\n",
      "36 / 50\n",
      "37 / 50\n",
      "38 / 50\n",
      "39 / 50\n",
      "40 / 50\n",
      "41 / 50\n",
      "42 / 50\n",
      "43 / 50\n",
      "44 / 50\n",
      "45 / 50\n",
      "46 / 50\n",
      "47 / 50\n",
      "48 / 50\n",
      "49 / 50\n",
      "50 / 50\n",
      "Box action space detected.\n",
      "Minimum action values: [-1. -1.]\n",
      "Maximum action values: [1. 1.]\n",
      "total extreme actions 9\n",
      "start collecting extreme action episode images\n",
      "1 / 3\n",
      "start collecting extreme action episode images\n",
      "2 / 3\n",
      "start collecting extreme action episode images\n",
      "3 / 3\n",
      "start collecting extreme action episode images\n",
      "4 / 3\n",
      "start collecting extreme action episode images\n",
      "5 / 3\n",
      "start collecting extreme action episode images\n",
      "6 / 3\n",
      "start collecting extreme action episode images\n",
      "7 / 3\n",
      "start collecting extreme action episode images\n",
      "8 / 3\n",
      "start collecting extreme action episode images\n",
      "9 / 3\n",
      "6522\n"
     ]
    }
   ],
   "source": [
    "i=collect_imgs(num_of_episodes=50,add_all_action_max=True)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc3f450",
   "metadata": {},
   "source": [
    "### VAE TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4dd115",
   "metadata": {},
   "source": [
    "# RL Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131c2b19",
   "metadata": {},
   "source": [
    "## get the VAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389392ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import ObservationWrapper\n",
    "from gymnasium.wrappers import PixelObservationWrapper, FrameStack\n",
    "from gymnasium.spaces import Box, Discrete\n",
    "import numpy as np\n",
    "import yaml\n",
    "from experiment import VAEXperiment\n",
    "from models import *\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=0.1):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "#ideas\n",
    "#maybe use wrapper to catch and save frames during RL model learning\n",
    "#alternative is to use the model afterwards to generate frames during a test run\n",
    "#\n",
    "#??return mu, std or sample or just mu??\n",
    "#\n",
    "class VAE_ENC(ObservationWrapper):\n",
    "    def __init__(self, env, vae,\n",
    "                 mean=0,std=0.1,\n",
    "                 size=(64,64)):\n",
    "        super().__init__(env)\n",
    "        #new obs space\n",
    "        self.observation_space = Box(shape=(10,), low=-np.inf, high=np.inf)\n",
    "\n",
    "        self.vae = vae\n",
    "        #transforms\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.size = size\n",
    "        \n",
    "        \n",
    "        \n",
    "    def observation(self, obs):\n",
    "        #get frame\n",
    "        #print(obs)\n",
    "        frame = obs['pixels']#.to('cuda')\n",
    "        #transform for VAE\n",
    "        val_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        AddGaussianNoise(self.mean, self.std),\n",
    "        transforms.Resize(self.size),\n",
    "        #transforms.Grayscale(),\n",
    "        #transforms.Normalize(self.mean, self.std),\n",
    "        ])\n",
    "        frame = val_transforms(frame) #(c,h,w)\n",
    "        frame = torch.unsqueeze(frame, 0)#.to(self.device) #make it (1,c,h,w)\n",
    "        enc = self.vae.encode(frame)    \n",
    "        enc = np.array([tensor.detach().cpu().numpy() for tensor in enc])\n",
    "        enc = np.array(enc[0][0])#, enc[1][0]]) ## mu, std #  give only mu?\n",
    "        return enc\n",
    "    \n",
    "def get_vae(version='version_0',log_directory='logs/BCE_sum_VAE/MSSIMVAE/'):\n",
    "\n",
    "    model_path=log_directory+'/'+version+'/hparams.yaml'\n",
    "    ckpt_path=log_directory+'/'+version+'/checkpoints/last.ckpt'\n",
    "\n",
    "    config = yaml.safe_load(open(model_path))\n",
    "    model = vae_models[config['model_params']['name']](**config['model_params'])\n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    experiment = VAEXperiment(model, config['exp_params'])\n",
    "    experiment.load_state_dict(ckpt['state_dict'])      \n",
    "    vae = experiment.model\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8b4bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = get_vae(version='version_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb95897a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSIMVAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (fc_mu): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  (fc_var): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  (decoder_input): Linear(in_features=10, out_features=2048, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Sequential(\n",
       "    (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       "  (mssim_loss): MSSIM()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a56213f",
   "metadata": {},
   "source": [
    "### make the env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e72c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\",\n",
    "                continuous= True,\n",
    "                gravity= -10.0,\n",
    "                enable_wind= False,\n",
    "                wind_power= 15.0,\n",
    "                turbulence_power= 1.5,\n",
    "                render_mode ='rgb_array')\n",
    "seed = 42\n",
    "env.reset(seed=seed)\n",
    "env = PixelObservationWrapper(env)\n",
    "env = VAE_ENC(env, vae)\n",
    "env = FrameStack(env, num_stack=2)\n",
    "env = Monitor(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15dddcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a6a3c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-inf, inf, (2, 10), float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7979fc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f56ac1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -5.5619473 ,  15.425905  ,  11.8485155 ,  -7.8212442 ,\n",
       "        24.54262   ,   8.515593  , -11.751206  ,  -0.42572248,\n",
       "        10.861605  , -32.383194  ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1c2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "  n_timesteps=float 5e5,\n",
    "  policy='MlpPolicy',\n",
    "  batch_size= 256,\n",
    "  learning_rate= 'lin_7.3e-4',\n",
    "  buffer_size= 1000000,\n",
    "  ent_coef= 'auto',\n",
    "  gamma= 0.99,\n",
    "  tau=0.01,\n",
    "  train_freq= 1,\n",
    "  gradient_steps= 1,\n",
    "  learning_starts= 10000,\n",
    "  policy_kwargs= dict(net_arch=[400, 300]),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51d44b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def linear_schedule(initial_value: float) -> Callable[[float], float]:\n",
    "    \"\"\"\n",
    "    Linear learning rate schedule.\n",
    "\n",
    "    :param initial_value: Initial learning rate.\n",
    "    :return: schedule that computes\n",
    "      current learning rate depending on remaining progress\n",
    "    \"\"\"\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        \"\"\"\n",
    "        Progress will decrease from 1 (beginning) to 0.\n",
    "\n",
    "        :param progress_remaining:\n",
    "        :return: current learning rate\n",
    "        \"\"\"\n",
    "        return progress_remaining * initial_value\n",
    "\n",
    "    return func\n",
    "\n",
    "\n",
    "models_dir = f\"RLmodels/LunarLander-v2_first_run_l10/\"\n",
    "logdir = f\"RLlogs/LunarLander-v2_first_run_l10/\"\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "\n",
    "    \n",
    "total_timesteps =  500000  # Total number of timesteps for training\n",
    "initial_lr = 7.3e-4  # Initial learning rate\n",
    "\n",
    "# Define the learning rate schedule\n",
    "lr_schedule = linear_schedule(initial_lr)\n",
    "    \n",
    "    \n",
    "model = SAC(   \n",
    "    policy='MlpPolicy',\n",
    "    env=env,\n",
    "    seed=seed,\n",
    "    batch_size= 256,\n",
    "    learning_rate= lr_schedule,\n",
    "    buffer_size= 1000000,\n",
    "    ent_coef= 'auto',\n",
    "    gamma= 0.99,\n",
    "    tau=0.01,\n",
    "    train_freq= 1,\n",
    "    gradient_steps= 1,\n",
    "    learning_starts= 10000,\n",
    "    policy_kwargs= dict(net_arch=[400, 300]),\n",
    "    use_sde= True,\n",
    "    tensorboard_log=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c25f6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration=3\n",
    "models_dir = f\"RLmodels/LunarLander-v2/\"+str(iteration)\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "agent_name = \"SAC\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7430dc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x7f31442e0100>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration=3\n",
    "agent_name = \"lunarlander_thirdVAE_l10_SAC\"\n",
    "callback = CheckpointCallback(save_freq=10000, save_path=models_dir+str(iteration))   \n",
    "#train the RL agent\n",
    "model.learn(total_timesteps=total_timesteps,callback=callback,tb_log_name=agent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fac30dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264bc036",
   "metadata": {},
   "source": [
    "## collect more images with RL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab6b23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent= SAC.load('RLmodels/LunarLander-v2_first_run_l10/1/rl_model_250000_steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2be0007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path='BCEv24_agent3_data'\n",
    "data_name='VAEruns_after_third_train'\n",
    "num_of_episodes=100\n",
    "i=7921\n",
    "for episode in range(num_of_episodes):\n",
    "    observation, info = env.reset()\n",
    "    done = False\n",
    "    while not done: \n",
    "        action, _states = agent.predict(observation, deterministic=True)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        #state, reward, terminated, truncated, info = env.step(action)\n",
    "        #print(terminated, truncated)\n",
    "        if terminated:\n",
    "            done = True\n",
    "        if truncated:\n",
    "            done = True\n",
    "        current_frame = env.render()\n",
    "\n",
    "        i+=1\n",
    "        im = Image.fromarray(np.array(current_frame))\n",
    "        im.save(save_path+'/'+data_name+'_'+str(i)+'.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a607b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99d623bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "images = []\n",
    "obs = model.env.reset()\n",
    "img = model.env.render(mode=\"rgb_array\")\n",
    "for i in range(450):\n",
    "    images.append(img)\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, _, _ ,_ = model.env.step(action)\n",
    "    img = model.env.render(mode=\"rgb_array\")\n",
    "\n",
    "imgs = [Image.fromarray(img) for img in images]\n",
    "# duration is the number of milliseconds between frames; this is 40 frames per second\n",
    "imgs[0].save(\"lunar_lander_sac_l10_v1.gif\", save_all=True, append_images=imgs[1:], duration=50, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f971e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = 'RLmodels/LunarLander-v2/11'\n",
    "# Get a list of all files in the directory\n",
    "files = os.listdir(model_folder)\n",
    "# Sort the files based on modification time (newest first)\n",
    "files.sort(key=lambda x: os.path.getmtime(os.path.join(model_folder, x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "940c8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = SAC.load(model_folder+'/'+files[0], env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c9cc2ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start collecting images with the model\n",
      "1 / 6\n",
      "2 / 6\n",
      "3 / 6\n",
      "4 / 6\n",
      "5 / 6\n",
      "6 / 6\n",
      "start collecting images with the model\n",
      "1 / 2\n",
      "2 / 2\n",
      "start collecting images with the model\n",
      "1 / 2\n",
      "2 / 2\n",
      "start collecting images with the model\n",
      "1 / 2\n",
      "2 / 2\n",
      "start collecting images with the model\n",
      "1 / 2\n",
      "2 / 2\n",
      "start collecting images with the model\n",
      "1 / 2\n",
      "2 / 2\n",
      "start collecting images with the model\n",
      "1 / 2\n",
      "2 / 2\n",
      "start collecting images with the model\n",
      "1 / 2\n",
      "2 / 2\n",
      "start collecting images with the model\n",
      "1 / 2\n",
      "2 / 2\n",
      "start collecting images with the model\n",
      "1 / 2\n",
      "2 / 2\n",
      "start collecting images with the model\n",
      "1 / 2\n",
      "2 / 2\n",
      "start collecting images with the model\n",
      "1 / 2\n",
      "2 / 2\n",
      "start collecting images with the model\n",
      "1 / 2\n",
      "2 / 2\n",
      "start collecting images with the model\n",
      "1 / 2\n",
      "2 / 2\n",
      "start collecting images with the model\n",
      "1 / 2\n",
      "2 / 2\n",
      "start collecting images with the model\n",
      "1 / 2\n",
      "2 / 2\n"
     ]
    }
   ],
   "source": [
    "num_of_imgs = 6377\n",
    "\n",
    "#collect new images with trained RL agent\n",
    "#aprox double number of images to train the vae on\n",
    "\n",
    "num_of_episodes = 2\n",
    "\n",
    "target_num_of_imgs = num_of_imgs*2\n",
    "#get ~ enough imgs, but its done via episodes.. so if the model becomes successful it would be way less imgs    \n",
    "num_of_imgs += collect_imgs(num_of_episodes=6, num_of_previous_imgs = num_of_imgs,\n",
    "            data_dir=\"Data/\",data_name = \"img_Data\",\n",
    "            model=model) \n",
    "\n",
    "\n",
    "\n",
    "model_folder = 'RLmodels/LunarLander-v2/11'\n",
    "# Get a list of all files in the directory\n",
    "files = os.listdir(model_folder)\n",
    "files.sort(key=lambda x: os.path.getmtime(os.path.join(model_folder, x)))\n",
    "for file in files:   \n",
    "    model0 = SAC.load(model_folder+'/'+file, env=env)\n",
    "\n",
    "    num_of_imgs += collect_imgs(num_of_episodes=num_of_episodes,num_of_previous_imgs = num_of_imgs,\n",
    "            data_dir=\"Data/\",data_name = \"lunar_Data\",\n",
    "            model=model0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925a900b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
